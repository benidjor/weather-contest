{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안개 발생 진단 분류 모델 AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_path(train_dataset_name, val_dataset_name, test_dataset_name):\n",
    "\n",
    "    # 작업 디렉토리 origin_dir에 선언\n",
    "    origin_dir = os.getcwd()\n",
    "\n",
    "    # \"..\" : 상위 디렉토리로 이동\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "    # 상위 디렉토리에 fog_data가 없다면 fog_data 폴더 생성\n",
    "    # (이미 폴더 있어도 exist_ok=True면 넘어감)\n",
    "    os.makedirs(\"fog_data\", exist_ok=True)\n",
    "\n",
    "    # train/test 데이터셋 경로 잡아준다\n",
    "    train_path = os.path.join(os.getcwd(), \"fog_data\", train_dataset_name)\n",
    "    val_path = os.path.join(os.getcwd(), \"fog_data\", val_dataset_name)\n",
    "    test_path = os.path.join(os.getcwd(), \"fog_data\", test_dataset_name)\n",
    "\n",
    "    # 운영체제가 윈도우일 경우, \"\\\\\"를 \"/\"로 바꿔줘야 한다\n",
    "    if os.name == \"nt\":\n",
    "        train_path = train_path.replace(\"\\\\\", \"/\")\n",
    "        val_path = val_path.replace(\"\\\\\", \"/\")\n",
    "        test_path = test_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "    # origin_dir로 경로 다시 변경 (초기화)\n",
    "    os.chdir(origin_dir)\n",
    "\n",
    "    return train_path, val_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 중간에 nan 제거해주고 이상치 제거한 train_df\n",
    "train_path, val_path, test_path = get_local_path(\"fog_train_dropped_no_outlier.csv\", \n",
    "                                                 \"fog_val_dropped_no_outlier.csv\", \n",
    "                                                 \"fog_test_dropped_no_outlier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.core.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSI 지수 함수 생성\n",
    "def csi_index(y_true, y_pred):\n",
    "\n",
    "    model_cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    H = (model_cm[0][0] + model_cm[1][1] + model_cm[2][2])\n",
    "    F = (model_cm[0][1] + model_cm[0][2] +\n",
    "            model_cm[1][0] + model_cm[1][2] +\n",
    "            model_cm[2][0] + model_cm[2][1] +\n",
    "            model_cm[3][0] + model_cm[3][1] + model_cm[3][2])\n",
    "    M = (model_cm[0][3] + model_cm[1][3] + model_cm[2][3])\n",
    "\n",
    "    model_csi = H / (H + F + M)\n",
    "\n",
    "    return model_csi\n",
    "\n",
    "ag_csi_scorer = make_scorer(name='CSI',\n",
    "                            score_func=csi_index,\n",
    "                            optimum=1,\n",
    "                            greater_is_better=True,\n",
    "                            needs_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 컬럼\n",
    "target = \"class\"\n",
    "\n",
    "# # 모델 생성시 사용할 컬럼 지정\n",
    "used_cols = train_df.drop(columns=[target, \"year\", \"vis1\", \"is_fog\", \"ws10_deg\", \"dew_point\"]).columns\n",
    "used_cols_target = train_df.drop(columns=[\"year\", \"vis1\", \"is_fog\", \"ws10_deg\", \"dew_point\"]).columns\n",
    "\n",
    "train = train_df[used_cols_target]\n",
    "# val = train_df[used_cols]\n",
    "val = val_df[used_cols_target]\n",
    "\n",
    "test = test_df[used_cols]\n",
    "\n",
    "# X_train = train_df[used_cols]\n",
    "# y_train = train_df[target]\n",
    "\n",
    "# X_val = val_df[used_cols]\n",
    "# y_val = val_df[target]\n",
    "\n",
    "# X_test = test_df[used_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular.configs.hyperparameter_configs import get_hyperparameter_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240624_184625\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.0\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          6\n",
      "Memory Avail:       7.29 GB / 15.95 GB (45.7%)\n",
      "Disk Space Avail:   1593.22 GB / 1862.39 GB (85.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels\\ag-20240624_184625\\ds_sub_fit\\sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240624_184625\\ds_sub_fit\\sub_fit_ho\"\n",
      "Train Data Rows:    1949462\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7355.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 395.11 MB (5.4% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 5.4% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['ws10_ms', 'ta', 'hm', 'sun10', 'ts', ...]\n",
      "\t\t('int', [])    : 6 | ['month', 'day', 'time', 'minute', 're', ...]\n",
      "\t\t('object', []) : 2 | ['stn_id', 'ws10_dir']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 2 | ['stn_id', 'ws10_dir']\n",
      "\t\t('float', [])     : 6 | ['ws10_ms', 'ta', 'hm', 'sun10', 'ts', ...]\n",
      "\t\t('int', [])       : 4 | ['month', 'day', 'time', 'minute']\n",
      "\t\t('int', ['bool']) : 2 | ['re', 'dew_reached']\n",
      "\t4.5s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 156.17 MB (2.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'CSI'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 596.24s of the 894.57s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.0908\t = Validation score   (CSI)\n",
      "\t29.36s\t = Training   runtime\n",
      "\t128.31s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 437.53s of the 735.86s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.1029\t = Validation score   (CSI)\n",
      "\t29.71s\t = Training   runtime\n",
      "\t130.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 276.34s of the 574.67s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 272.2s of the 570.53s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 34. Best iteration is:\n",
      "\t[33]\tvalid_set's multi_logloss: 0.047481\tvalid_set's CSI: 0.0106993\n",
      "\tRan out of time, early stopping on iteration 35. Best iteration is:\n",
      "\t[35]\tvalid_set's multi_logloss: 0.0468667\tvalid_set's CSI: 0.0103211\n",
      "\tRan out of time, early stopping on iteration 36. Best iteration is:\n",
      "\t[36]\tvalid_set's multi_logloss: 0.0461999\tvalid_set's CSI: 0.0107034\n",
      "\tRan out of time, early stopping on iteration 37. Best iteration is:\n",
      "\t[37]\tvalid_set's multi_logloss: 0.0461169\tvalid_set's CSI: 0.0114329\n",
      "\tRan out of time, early stopping on iteration 40. Best iteration is:\n",
      "\t[40]\tvalid_set's multi_logloss: 0.0462021\tvalid_set's CSI: 0.015619\n",
      "\tRan out of time, early stopping on iteration 69. Best iteration is:\n",
      "\t[69]\tvalid_set's multi_logloss: 0.0439106\tvalid_set's CSI: 0.024696\n",
      "\t0.0106\t = Validation score   (CSI)\n",
      "\t255.14s\t = Training   runtime\n",
      "\t2.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 12.73s of the 311.07s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.0610698\tvalid_set's CSI: 0.0573013\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 9.91s of the 308.24s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.199 GB out of 8.773 GB available memory (59.257%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.24 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini_BAG_L1... Skipping this model.\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 9.28s of the 307.61s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.199 GB out of 8.766 GB available memory (59.306%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.24 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 8.66s of the 306.99s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 4.39s of the 302.72s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.199 GB out of 8.790 GB available memory (59.143%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.23 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesGini_BAG_L1... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3.75s of the 302.09s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.199 GB out of 8.793 GB available memory (59.119%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.23 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3.13s of the 301.46s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 288.85s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 1.0}\n",
      "\t0.1029\t = Validation score   (CSI)\n",
      "\t11.68s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 276.79s of the 276.46s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 270.45s of the 270.11s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 31. Best iteration is:\n",
      "\t[31]\tvalid_set's multi_logloss: 0.0414652\tvalid_set's CSI: 0.110991\n",
      "\tRan out of time, early stopping on iteration 32. Best iteration is:\n",
      "\t[31]\tvalid_set's multi_logloss: 0.0421008\tvalid_set's CSI: 0.101845\n",
      "\tRan out of time, early stopping on iteration 34. Best iteration is:\n",
      "\t[34]\tvalid_set's multi_logloss: 0.0411619\tvalid_set's CSI: 0.109202\n",
      "\tRan out of time, early stopping on iteration 35. Best iteration is:\n",
      "\t[35]\tvalid_set's multi_logloss: 0.0413154\tvalid_set's CSI: 0.0939187\n",
      "\tRan out of time, early stopping on iteration 36. Best iteration is:\n",
      "\t[35]\tvalid_set's multi_logloss: 0.0408562\tvalid_set's CSI: 0.107259\n",
      "\tRan out of time, early stopping on iteration 38. Best iteration is:\n",
      "\t[38]\tvalid_set's multi_logloss: 0.0413553\tvalid_set's CSI: 0.0856115\n",
      "\tRan out of time, early stopping on iteration 60. Best iteration is:\n",
      "\t[60]\tvalid_set's multi_logloss: 0.0402927\tvalid_set's CSI: 0.119371\n",
      "\t0.1044\t = Validation score   (CSI)\n",
      "\t255.39s\t = Training   runtime\n",
      "\t2.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 10.08s of the 9.75s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.0530024\tvalid_set's CSI: 0.118431\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 0.88s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t0.1044\t = Validation score   (CSI)\n",
      "\t15.08s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 914.76s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 6537.2 rows/s (243683 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240624_184625\\ds_sub_fit\\sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBMXT_BAG_L2       0.119186   0.104368         CSI       38.342414     263.688180  569.593697                 2.285660                2.327864         255.385426            2       True          5\n",
      "1    WeightedEnsemble_L3       0.119186   0.104368         CSI       38.351413     263.925184  584.677364                 0.009000                0.237004          15.083667            3       True          6\n",
      "2  KNeighborsDist_BAG_L1       0.109555   0.102883         CSI       17.973153     130.477354   29.708049                17.973153              130.477354          29.708049            1       True          2\n",
      "3    WeightedEnsemble_L2       0.109555   0.102883         CSI       17.982151     130.702353   41.388259                 0.008999                0.225000          11.680209            2       True          4\n",
      "4  KNeighborsUnif_BAG_L1       0.098736   0.090782         CSI       15.525732     128.312842   29.358242                15.525732              128.312842          29.358242            1       True          1\n",
      "5      LightGBMXT_BAG_L1       0.000000   0.010597         CSI        2.557870       2.570121  255.141980                 2.557870                2.570121         255.141980            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t956s\t = DyStack   runtime |\t2644s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2644s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240624_184625\"\n",
      "Train Data Rows:    2193145\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8760.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 444.50 MB (5.1% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 5.1% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['ws10_ms', 'ta', 'hm', 'sun10', 'ts', ...]\n",
      "\t\t('int', [])    : 6 | ['month', 'day', 'time', 'minute', 're', ...]\n",
      "\t\t('object', []) : 2 | ['stn_id', 'ws10_dir']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 2 | ['stn_id', 'ws10_dir']\n",
      "\t\t('float', [])     : 6 | ['ws10_ms', 'ta', 'hm', 'sun10', 'ts', ...]\n",
      "\t\t('int', [])       : 4 | ['month', 'day', 'time', 'minute']\n",
      "\t\t('int', ['bool']) : 2 | ['re', 'dew_reached']\n",
      "\t4.7s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 175.69 MB (2.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'CSI'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1758.78s of the 2638.82s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.0996\t = Validation score   (CSI)\n",
      "\t31.08s\t = Training   runtime\n",
      "\t119.75s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1606.85s of the 2486.89s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.1115\t = Validation score   (CSI)\n",
      "\t31.1s\t = Training   runtime\n",
      "\t139.65s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1434.99s of the 2315.03s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\t0.062\t = Validation score   (CSI)\n",
      "\t1294.84s\t = Training   runtime\n",
      "\t13.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 124.11s of the 1004.15s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 13. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.0650129\tvalid_set's CSI: 0\n",
      "\tRan out of time, early stopping on iteration 13. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.0650294\tvalid_set's CSI: 0\n",
      "\tRan out of time, early stopping on iteration 13. Best iteration is:\n",
      "\t[13]\tvalid_set's multi_logloss: 0.0510515\tvalid_set's CSI: 0.00136193\n",
      "\tRan out of time, early stopping on iteration 14. Best iteration is:\n",
      "\t[14]\tvalid_set's multi_logloss: 0.0518224\tvalid_set's CSI: 0.0034002\n",
      "\tRan out of time, early stopping on iteration 14. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.0652357\tvalid_set's CSI: 0\n",
      "\tRan out of time, early stopping on iteration 15. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.0652277\tvalid_set's CSI: 0\n",
      "\tRan out of time, early stopping on iteration 16. Best iteration is:\n",
      "\t[16]\tvalid_set's multi_logloss: 0.0501183\tvalid_set's CSI: 0.0095141\n",
      "\tRan out of time, early stopping on iteration 18. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.0648719\tvalid_set's CSI: 0\n",
      "\t0.0018\t = Validation score   (CSI)\n",
      "\t118.82s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2.75s of the 882.78s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.061719\tvalid_set's CSI: 0.0486251\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 879.16s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 1.0}\n",
      "\t0.1115\t = Validation score   (CSI)\n",
      "\t15.07s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 863.63s of the 863.11s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "Metric CSI is not supported by this model - using log_loss instead\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 4)\n",
      "\t0.1471\t = Validation score   (CSI)\n",
      "\t773.74s\t = Training   runtime\n",
      "\t13.39s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 71.93s of the 71.41s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 6. Best iteration is:\n",
      "\t[6]\tvalid_set's multi_logloss: 0.0459156\tvalid_set's CSI: 0.123682\n",
      "\tTime limit exceeded... Skipping LightGBMXT_BAG_L2.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 60.64s of the 60.12s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 5. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_logloss: 0.0506231\tvalid_set's CSI: 0.14428\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 50.62s of the 50.11s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.848 GB out of 8.911 GB available memory (65.628%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.36 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini_BAG_L2... Skipping this model.\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 48.07s of the 47.56s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.848 GB out of 8.915 GB available memory (65.604%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.36 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr_BAG_L2... Skipping this model.\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 45.52s of the 45.01s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L2.\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 37.86s of the 37.35s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.848 GB out of 8.949 GB available memory (65.354%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.36 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesGini_BAG_L2... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 35.32s of the 34.8s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.848 GB out of 8.934 GB available memory (65.464%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.36 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesEntr_BAG_L2... Skipping this model.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 32.78s of the 32.26s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L2.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 13.24s of the 12.72s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -14.82s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 1.0}\n",
      "\t0.1471\t = Validation score   (CSI)\n",
      "\t18.5s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2678.28s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 4601.5 rows/s (274144 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240624_184625\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=\"class\", eval_metric=ag_csi_scorer).fit(\n",
    "    train_data=train,\n",
    "    presets='best_quality',\n",
    "    # time_limit=500,  # 학습 시간 제한 (초 단위)\n",
    "    # ag_args_fit={'num_gpus': 1}  # GPU 사용 설정\n",
    "    num_gpus=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                    model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetFastAI_BAG_L2   0.147103         CSI     286.521387  2249.585996               13.392524         773.743898            2       True          6\n",
      "1     WeightedEnsemble_L3   0.147103         CSI     286.785384  2268.081046                0.263997          18.495050            3       True          7\n",
      "2   KNeighborsDist_BAG_L1   0.111520         CSI     139.653692    31.104553              139.653692          31.104553            1       True          2\n",
      "3     WeightedEnsemble_L2   0.111520         CSI     139.911692    46.174592                0.258001          15.070039            2       True          5\n",
      "4   KNeighborsUnif_BAG_L1   0.099642         CSI     119.749321    31.082488              119.749321          31.082488            1       True          1\n",
      "5  NeuralNetFastAI_BAG_L1   0.062011         CSI      13.054852  1294.839772               13.054852        1294.839772            1       True          3\n",
      "6       LightGBMXT_BAG_L1   0.001787         CSI       0.670999   118.815284                0.670999         118.815284            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_KNN'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 2 | ['stn_id', 'ws10_dir']\n",
      "('float', [])     : 6 | ['ws10_ms', 'ta', 'hm', 'sun10', 'ts', ...]\n",
      "('int', [])       : 4 | ['month', 'day', 'time', 'minute']\n",
      "('int', ['bool']) : 2 | ['re', 'dew_reached']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'NeuralNetFastAI_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.09964184731385485,\n",
       "  'KNeighborsDist_BAG_L1': 0.11152013019723331,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.06201066133599867,\n",
       "  'LightGBMXT_BAG_L1': 0.0017868538608806638,\n",
       "  'WeightedEnsemble_L2': 0.11152013019723331,\n",
       "  'NeuralNetFastAI_BAG_L2': 0.14710276600040378,\n",
       "  'WeightedEnsemble_L3': 0.14710276600040378},\n",
       " 'model_best': 'WeightedEnsemble_L3',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': ['KNeighborsUnif_BAG_L1'],\n",
       "  'KNeighborsDist_BAG_L1': ['KNeighborsDist_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'NeuralNetFastAI_BAG_L2': ['NeuralNetFastAI_BAG_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3']},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 31.08248805999756,\n",
       "  'KNeighborsDist_BAG_L1': 31.10455322265625,\n",
       "  'NeuralNetFastAI_BAG_L1': 1294.8397724628448,\n",
       "  'LightGBMXT_BAG_L1': 118.81528353691101,\n",
       "  'WeightedEnsemble_L2': 15.070038557052612,\n",
       "  'NeuralNetFastAI_BAG_L2': 773.7438983917236,\n",
       "  'WeightedEnsemble_L3': 18.495050191879272},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 119.74932074546814,\n",
       "  'KNeighborsDist_BAG_L1': 139.65369153022766,\n",
       "  'NeuralNetFastAI_BAG_L1': 13.054851531982422,\n",
       "  'LightGBMXT_BAG_L1': 0.6709985733032227,\n",
       "  'WeightedEnsemble_L2': 0.25800061225891113,\n",
       "  'NeuralNetFastAI_BAG_L2': 13.392524480819702,\n",
       "  'WeightedEnsemble_L3': 0.26399731636047363},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'num_classes': 4,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                     model  score_val eval_metric  pred_time_val     fit_time  \\\n",
       " 0  NeuralNetFastAI_BAG_L2   0.147103         CSI     286.521387  2249.585996   \n",
       " 1     WeightedEnsemble_L3   0.147103         CSI     286.785384  2268.081046   \n",
       " 2   KNeighborsDist_BAG_L1   0.111520         CSI     139.653692    31.104553   \n",
       " 3     WeightedEnsemble_L2   0.111520         CSI     139.911692    46.174592   \n",
       " 4   KNeighborsUnif_BAG_L1   0.099642         CSI     119.749321    31.082488   \n",
       " 5  NeuralNetFastAI_BAG_L1   0.062011         CSI      13.054852  1294.839772   \n",
       " 6       LightGBMXT_BAG_L1   0.001787         CSI       0.670999   118.815284   \n",
       " \n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0               13.392524         773.743898            2       True   \n",
       " 1                0.263997          18.495050            3       True   \n",
       " 2              139.653692          31.104553            1       True   \n",
       " 3                0.258001          15.070039            2       True   \n",
       " 4              119.749321          31.082488            1       True   \n",
       " 5               13.054852        1294.839772            1       True   \n",
       " 6                0.670999         118.815284            1       True   \n",
       " \n",
       "    fit_order  \n",
       " 0          6  \n",
       " 1          7  \n",
       " 2          2  \n",
       " 3          5  \n",
       " 4          1  \n",
       " 5          3  \n",
       " 6          4  }"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111520</td>\n",
       "      <td>CSI</td>\n",
       "      <td>129.177168</td>\n",
       "      <td>139.653692</td>\n",
       "      <td>31.104553</td>\n",
       "      <td>129.177168</td>\n",
       "      <td>139.653692</td>\n",
       "      <td>31.104553</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111520</td>\n",
       "      <td>CSI</td>\n",
       "      <td>129.265444</td>\n",
       "      <td>139.911692</td>\n",
       "      <td>46.174592</td>\n",
       "      <td>0.088276</td>\n",
       "      <td>0.258001</td>\n",
       "      <td>15.070039</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.890147</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>CSI</td>\n",
       "      <td>448.814812</td>\n",
       "      <td>286.521387</td>\n",
       "      <td>2249.585996</td>\n",
       "      <td>109.944973</td>\n",
       "      <td>13.392524</td>\n",
       "      <td>773.743898</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.890147</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>CSI</td>\n",
       "      <td>448.877813</td>\n",
       "      <td>286.785384</td>\n",
       "      <td>2268.081046</td>\n",
       "      <td>0.063001</td>\n",
       "      <td>0.263997</td>\n",
       "      <td>18.495050</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.248162</td>\n",
       "      <td>0.099642</td>\n",
       "      <td>CSI</td>\n",
       "      <td>102.678838</td>\n",
       "      <td>119.749321</td>\n",
       "      <td>31.082488</td>\n",
       "      <td>102.678838</td>\n",
       "      <td>119.749321</td>\n",
       "      <td>31.082488</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.060813</td>\n",
       "      <td>0.062011</td>\n",
       "      <td>CSI</td>\n",
       "      <td>101.534393</td>\n",
       "      <td>13.054852</td>\n",
       "      <td>1294.839772</td>\n",
       "      <td>101.534393</td>\n",
       "      <td>13.054852</td>\n",
       "      <td>1294.839772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>CSI</td>\n",
       "      <td>5.479440</td>\n",
       "      <td>0.670999</td>\n",
       "      <td>118.815284</td>\n",
       "      <td>5.479440</td>\n",
       "      <td>0.670999</td>\n",
       "      <td>118.815284</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0   KNeighborsDist_BAG_L1    1.000000   0.111520         CSI      129.177168   \n",
       "1     WeightedEnsemble_L2    1.000000   0.111520         CSI      129.265444   \n",
       "2  NeuralNetFastAI_BAG_L2    0.890147   0.147103         CSI      448.814812   \n",
       "3     WeightedEnsemble_L3    0.890147   0.147103         CSI      448.877813   \n",
       "4   KNeighborsUnif_BAG_L1    0.248162   0.099642         CSI      102.678838   \n",
       "5  NeuralNetFastAI_BAG_L1    0.060813   0.062011         CSI      101.534393   \n",
       "6       LightGBMXT_BAG_L1    0.000000   0.001787         CSI        5.479440   \n",
       "\n",
       "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0     139.653692    31.104553               129.177168   \n",
       "1     139.911692    46.174592                 0.088276   \n",
       "2     286.521387  2249.585996               109.944973   \n",
       "3     286.785384  2268.081046                 0.063001   \n",
       "4     119.749321    31.082488               102.678838   \n",
       "5      13.054852  1294.839772               101.534393   \n",
       "6       0.670999   118.815284                 5.479440   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0              139.653692          31.104553            1       True   \n",
       "1                0.258001          15.070039            2       True   \n",
       "2               13.392524         773.743898            2       True   \n",
       "3                0.263997          18.495050            3       True   \n",
       "4              119.749321          31.082488            1       True   \n",
       "5               13.054852        1294.839772            1       True   \n",
       "6                0.670999         118.815284            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          2  \n",
       "1          5  \n",
       "2          6  \n",
       "3          7  \n",
       "4          1  \n",
       "5          3  \n",
       "6          4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_board1 = predictor.leaderboard(train, silent=True)\n",
    "ld_board1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.146188</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>CSI</td>\n",
       "      <td>173.377162</td>\n",
       "      <td>286.521387</td>\n",
       "      <td>2249.585996</td>\n",
       "      <td>40.465162</td>\n",
       "      <td>13.392524</td>\n",
       "      <td>773.743898</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.146188</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>CSI</td>\n",
       "      <td>173.408161</td>\n",
       "      <td>286.785384</td>\n",
       "      <td>2268.081046</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.263997</td>\n",
       "      <td>18.495050</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.111520</td>\n",
       "      <td>CSI</td>\n",
       "      <td>46.357697</td>\n",
       "      <td>139.653692</td>\n",
       "      <td>31.104553</td>\n",
       "      <td>46.357697</td>\n",
       "      <td>139.653692</td>\n",
       "      <td>31.104553</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.111520</td>\n",
       "      <td>CSI</td>\n",
       "      <td>46.394694</td>\n",
       "      <td>139.911692</td>\n",
       "      <td>46.174592</td>\n",
       "      <td>0.036998</td>\n",
       "      <td>0.258001</td>\n",
       "      <td>15.070039</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.096025</td>\n",
       "      <td>0.099642</td>\n",
       "      <td>CSI</td>\n",
       "      <td>46.547238</td>\n",
       "      <td>119.749321</td>\n",
       "      <td>31.082488</td>\n",
       "      <td>46.547238</td>\n",
       "      <td>119.749321</td>\n",
       "      <td>31.082488</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.060917</td>\n",
       "      <td>0.062011</td>\n",
       "      <td>CSI</td>\n",
       "      <td>37.943581</td>\n",
       "      <td>13.054852</td>\n",
       "      <td>1294.839772</td>\n",
       "      <td>37.943581</td>\n",
       "      <td>13.054852</td>\n",
       "      <td>1294.839772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>CSI</td>\n",
       "      <td>2.063483</td>\n",
       "      <td>0.670999</td>\n",
       "      <td>118.815284</td>\n",
       "      <td>2.063483</td>\n",
       "      <td>0.670999</td>\n",
       "      <td>118.815284</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0  NeuralNetFastAI_BAG_L2    0.146188   0.147103         CSI      173.377162   \n",
       "1     WeightedEnsemble_L3    0.146188   0.147103         CSI      173.408161   \n",
       "2   KNeighborsDist_BAG_L1    0.104877   0.111520         CSI       46.357697   \n",
       "3     WeightedEnsemble_L2    0.104877   0.111520         CSI       46.394694   \n",
       "4   KNeighborsUnif_BAG_L1    0.096025   0.099642         CSI       46.547238   \n",
       "5  NeuralNetFastAI_BAG_L1    0.060917   0.062011         CSI       37.943581   \n",
       "6       LightGBMXT_BAG_L1    0.000000   0.001787         CSI        2.063483   \n",
       "\n",
       "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0     286.521387  2249.585996                40.465162   \n",
       "1     286.785384  2268.081046                 0.031000   \n",
       "2     139.653692    31.104553                46.357697   \n",
       "3     139.911692    46.174592                 0.036998   \n",
       "4     119.749321    31.082488                46.547238   \n",
       "5      13.054852  1294.839772                37.943581   \n",
       "6       0.670999   118.815284                 2.063483   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0               13.392524         773.743898            2       True   \n",
       "1                0.263997          18.495050            3       True   \n",
       "2              139.653692          31.104553            1       True   \n",
       "3                0.258001          15.070039            2       True   \n",
       "4              119.749321          31.082488            1       True   \n",
       "5               13.054852        1294.839772            1       True   \n",
       "6                0.670999         118.815284            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          7  \n",
       "2          2  \n",
       "3          5  \n",
       "4          1  \n",
       "5          3  \n",
       "6          4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_board2 = predictor.leaderboard(val, silent=True)\n",
    "ld_board2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.146188</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>CSI</td>\n",
       "      <td>173.377162</td>\n",
       "      <td>286.521387</td>\n",
       "      <td>2249.585996</td>\n",
       "      <td>40.465162</td>\n",
       "      <td>13.392524</td>\n",
       "      <td>773.743898</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.146188</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>CSI</td>\n",
       "      <td>173.408161</td>\n",
       "      <td>286.785384</td>\n",
       "      <td>2268.081046</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.263997</td>\n",
       "      <td>18.495050</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.111520</td>\n",
       "      <td>CSI</td>\n",
       "      <td>46.357697</td>\n",
       "      <td>139.653692</td>\n",
       "      <td>31.104553</td>\n",
       "      <td>46.357697</td>\n",
       "      <td>139.653692</td>\n",
       "      <td>31.104553</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.111520</td>\n",
       "      <td>CSI</td>\n",
       "      <td>46.394694</td>\n",
       "      <td>139.911692</td>\n",
       "      <td>46.174592</td>\n",
       "      <td>0.036998</td>\n",
       "      <td>0.258001</td>\n",
       "      <td>15.070039</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.096025</td>\n",
       "      <td>0.099642</td>\n",
       "      <td>CSI</td>\n",
       "      <td>46.547238</td>\n",
       "      <td>119.749321</td>\n",
       "      <td>31.082488</td>\n",
       "      <td>46.547238</td>\n",
       "      <td>119.749321</td>\n",
       "      <td>31.082488</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.060917</td>\n",
       "      <td>0.062011</td>\n",
       "      <td>CSI</td>\n",
       "      <td>37.943581</td>\n",
       "      <td>13.054852</td>\n",
       "      <td>1294.839772</td>\n",
       "      <td>37.943581</td>\n",
       "      <td>13.054852</td>\n",
       "      <td>1294.839772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>CSI</td>\n",
       "      <td>2.063483</td>\n",
       "      <td>0.670999</td>\n",
       "      <td>118.815284</td>\n",
       "      <td>2.063483</td>\n",
       "      <td>0.670999</td>\n",
       "      <td>118.815284</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0  NeuralNetFastAI_BAG_L2    0.146188   0.147103         CSI      173.377162   \n",
       "1     WeightedEnsemble_L3    0.146188   0.147103         CSI      173.408161   \n",
       "2   KNeighborsDist_BAG_L1    0.104877   0.111520         CSI       46.357697   \n",
       "3     WeightedEnsemble_L2    0.104877   0.111520         CSI       46.394694   \n",
       "4   KNeighborsUnif_BAG_L1    0.096025   0.099642         CSI       46.547238   \n",
       "5  NeuralNetFastAI_BAG_L1    0.060917   0.062011         CSI       37.943581   \n",
       "6       LightGBMXT_BAG_L1    0.000000   0.001787         CSI        2.063483   \n",
       "\n",
       "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0     286.521387  2249.585996                40.465162   \n",
       "1     286.785384  2268.081046                 0.031000   \n",
       "2     139.653692    31.104553                46.357697   \n",
       "3     139.911692    46.174592                 0.036998   \n",
       "4     119.749321    31.082488                46.547238   \n",
       "5      13.054852  1294.839772                37.943581   \n",
       "6       0.670999   118.815284                 2.063483   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0               13.392524         773.743898            2       True   \n",
       "1                0.263997          18.495050            3       True   \n",
       "2              139.653692          31.104553            1       True   \n",
       "3                0.258001          15.070039            2       True   \n",
       "4              119.749321          31.082488            1       True   \n",
       "5               13.054852        1294.839772            1       True   \n",
       "6                0.670999         118.815284            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          7  \n",
       "2          2  \n",
       "3          5  \n",
       "4          1  \n",
       "5          3  \n",
       "6          4  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_board2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autogluon 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count        500\n",
      "unique         2\n",
      "top        <=50K\n",
      "freq         365\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "label = 'class'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240624_182441\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.0\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          6\n",
      "Memory Avail:       8.23 GB / 15.95 GB (51.6%)\n",
      "Disk Space Avail:   1594.22 GB / 1862.39 GB (85.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240624_182441\"\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8421.20 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t2.85s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t7.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.86\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'XGBoost': 1.0}\n",
      "\t0.86\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.53s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 20001.4 rows/s (100 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240624_182441\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(\n",
    "    train_data=train_data,\n",
    "    num_gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>169085</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>226203</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>54260</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>176262</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>241185</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt      education  education-num  \\\n",
       "0   31            Private  169085           11th              7   \n",
       "1   17   Self-emp-not-inc  226203           12th              8   \n",
       "2   47            Private   54260      Assoc-voc             11   \n",
       "3   21            Private  176262   Some-college             10   \n",
       "4   17            Private  241185           12th              8   \n",
       "\n",
       "        marital-status        occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse             Sales         Wife   White   Female   \n",
       "1        Never-married             Sales    Own-child   White     Male   \n",
       "2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "3        Never-married   Exec-managerial    Own-child   White   Female   \n",
       "4        Never-married    Prof-specialty    Own-child   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0             0             0              20   United-States  \n",
       "1             0             0              45   United-States  \n",
       "2             0          1887              60   United-States  \n",
       "3             0             0              30   United-States  \n",
       "4             0             0              20   United-States  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]  # values to predict\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      " 0        <=50K\n",
      "1        <=50K\n",
      "2         >50K\n",
      "3        <=50K\n",
      "4        <=50K\n",
      "         ...  \n",
      "9764     <=50K\n",
      "9765     <=50K\n",
      "9766     <=50K\n",
      "9767     <=50K\n",
      "9768     <=50K\n",
      "Name: class, Length: 9769, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240624_164420\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.0\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          6\n",
      "Memory Avail:       5.26 GB / 15.95 GB (33.0%)\n",
      "Disk Space Avail:   1601.48 GB / 1862.39 GB (86.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240624_164420\"\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5378.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_epochs': 5},\n",
      "\t'GBM': {'num_boost_round': 10},\n",
      "\t'CAT': {'iterations': 10},\n",
      "\t'XGB': {'n_estimators': 10},\n",
      "}\n",
      "Fitting 4 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.78\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.75\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'CatBoost': 1.0}\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.51s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 20000.5 rows/s (100 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240624_164420\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.827618</td>\n",
       "      <td>0.83</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.035997</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.035997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.818098</td>\n",
       "      <td>0.84</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.023998</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.424512</td>\n",
       "      <td>0.023998</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.424512</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.818098</td>\n",
       "      <td>0.84</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.025998</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.461511</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.796806</td>\n",
       "      <td>0.78</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.348650</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.348650</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.786263</td>\n",
       "      <td>0.75</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.060001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.451998</td>\n",
       "      <td>0.060001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.451998</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0              XGBoost    0.827618       0.83    accuracy        0.024001   \n",
       "1             CatBoost    0.818098       0.84    accuracy        0.023998   \n",
       "2  WeightedEnsemble_L2    0.818098       0.84    accuracy        0.025998   \n",
       "3             LightGBM    0.796806       0.78    accuracy        0.067000   \n",
       "4       NeuralNetTorch    0.786263       0.75    accuracy        0.060001   \n",
       "\n",
       "   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.006003  0.035997                 0.024001                0.006003   \n",
       "1       0.004000  0.424512                 0.023998                0.004000   \n",
       "2       0.005000  0.461511                 0.001999                0.001000   \n",
       "3       0.004000  0.348650                 0.067000                0.004000   \n",
       "4       0.010000  0.451998                 0.060001                0.010000   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.035997            1       True          3  \n",
       "1           0.424512            1       True          2  \n",
       "2           0.036999            2       True          5  \n",
       "3           0.348650            1       True          1  \n",
       "4           0.451998            1       True          4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(label=label).fit(train_data, hyperparameters='toy')\n",
    "\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15946767276091886305\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow device 확인\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb (cpu): 소요시간: 18.49636197090149 초\n",
      "xgb (gpu): 소요시간: 7.452618598937988 초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.datasets import make_regression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def model_test(model_name, model):\n",
    "    x, y = make_regression(n_samples=100000, n_features=100)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(x, y)\n",
    "    end_time = time.time()\n",
    "    return f'{model_name}: 소요시간: {(end_time - start_time)} 초'\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=1000, \n",
    "                   learning_rate=0.01, \n",
    "                   subsample=0.8, \n",
    "                   colsample_bytree=0.8,\n",
    "                   objective='reg:squarederror', \n",
    "                  )\n",
    "\n",
    "print(model_test('xgb (cpu)', xgb))\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=1000, \n",
    "                   learning_rate=0.01, \n",
    "                   subsample=0.8, \n",
    "                   colsample_bytree=0.8,\n",
    "                   objective='reg:squarederror', \n",
    "                   tree_method='gpu_hist')\n",
    "\n",
    "print(model_test('xgb (gpu)', xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
